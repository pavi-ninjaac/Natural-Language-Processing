{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavithra/.local/lib/python3.8/site-packages/datasets/load.py:1486: FutureWarning: The repository for alexfabbri/multi_news contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/alexfabbri/multi_news\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 44972\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 5622\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary'],\n",
       "        num_rows: 5622\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "multi_news_dataset = load_dataset(\"alexfabbri/multi_news\")\n",
    "multi_news_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_news_dataset[\"train\"][\"document\"][100].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 18:10:46.533706: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393637888 exceeds 10% of free system memory.\n",
      "2024-05-26 18:10:47.033588: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393637888 exceeds 10% of free system memory.\n",
      "2024-05-26 18:10:47.102048: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393637888 exceeds 10% of free system memory.\n",
      "2024-05-26 18:10:53.401002: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393637888 exceeds 10% of free system memory.\n",
      "2024-05-26 18:10:54.554373: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 393637888 exceeds 10% of free system memory.\n",
      "All PyTorch model weights were used when initializing TFPegasusForConditionalGeneration.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFPegasusForConditionalGeneration were not initialized from the PyTorch model and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# gonna use this model\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-cnn_dailymail\")\n",
    "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"google/pegasus-cnn_dailymail\", from_pt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [181, 1467, 4011, 118, 161, 1301, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁some', 'h', 'ting', '▁for', '▁my', '▁understanding', '</s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play with the tockenizer a little bit\n",
    "a = tokenizer(\"somehting for my understanding\")\n",
    "print(a)\n",
    "tokenizer.convert_ids_to_tokens(a[\"input_ids\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "type(multi_news_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.tokenization_utils import BatchEncoding\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "\n",
    "def tokenize_sentence(dataset: DatasetDict, input_feature: str, response_feature: str) -> BatchEncoding:\n",
    "    model_input = tokenizer(dataset[input_feature])\n",
    "    print(type(model_input))\n",
    "    labels = tokenizer(dataset[response_feature])\n",
    "    print(labels)\n",
    "    model_input[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_input\n",
    "\n",
    "tokenized_data = multi_news_dataset.map(tokenize_sentence, batched=True)\n",
    "print(type(tokenized_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
